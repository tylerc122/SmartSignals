#!/usr/bin/env python3
"""
Test Trained Traffic Signal RL Agent

This script loads the trained AI agent and demonstrates it controlling
traffic lights in real time. It will run 3 episodes of 10 minutes each.

"""

import os
import sys
import time
import numpy as np

# Add src directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from stable_baselines3 import PPO
from environments.sumo_traffic_env import SumoTrafficEnv



def load_trained_agent(model_path):
    """Load the trained PPO agent."""
    print(f"Loading trained agent from: {model_path}")
    model = PPO.load(model_path)
    print("‚úÖ AI agent loaded successfully!")
    return model


def create_demo_environment(use_gui=False):
    """Create environment for demonstration with longer episodes."""
    env = SumoTrafficEnv(
        sumo_config_file="sumo_scenarios/cross_intersection.sumocfg",
        step_duration=5,  # 5 seconds per RL step
        episode_length=600  # 10 minutes of simulation time for short demo
    )
    
    if use_gui:
        # Set DISPLAY environment variable for Mac GUI (crucial!)
        os.environ['DISPLAY'] = ':0.0'
        env.sumo_cmd = ["sumo-gui", "-c", env.sumo_config_file, 
                       "--no-step-log", "--no-warnings"]
        print("GUI mode enabled")
    else:
        print("Headless mode")
    
    return env


def demonstrate_ai_control(model, env, episodes=3, use_gui=False):
    """
    Demonstrate the AI controlling traffic for multiple episodes.
    
    Args:
        model: Trained PPO agent
        env: SUMO environment
        episodes: Number of episodes to run
        use_gui: Whether using GUI (default: False for speed)
    """
    print(f"\nStarting AI Traffic Control Demo")
    print(f"Running {episodes} episodes (10 minutes of traffic each)")
    print("Headless mode")
    print("=" * 60)
    
    episode_rewards = []
    episode_stats = []
    
    for episode in range(episodes):
        print(f"\nüìã Episode {episode + 1}/{episodes}")
        print("-" * 40)
        
        # Reset environment
        obs, info = env.reset()
        total_reward = 0
        step_count = 0
        
        # Track statistics
        total_waiting_time = 0
        total_vehicles_served = 0
        phase_changes = 0
        last_phase = None
        
        done = False
        while not done:
            # AI makes decision
            action, _states = model.predict(obs, deterministic=True)
            
            # Execute action
            obs, reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated
            
            # Update statistics
            total_reward += reward
            step_count += 1
            
            if 'total_waiting_time' in info:
                total_waiting_time = info['total_waiting_time']
            
            if 'current_phase' in info:
                current_phase = info['current_phase']
                if last_phase is not None and current_phase != last_phase:
                    phase_changes += 1
                last_phase = current_phase
            
            # No delays needed in headless mode - let it run fast!
            
            # Print periodic updates
            if step_count % 20 == 0:  # Every 100 seconds of simulation
                print(f"  Step {step_count:3d}: Reward = {total_reward:6.1f}, "
                      f"Waiting time = {total_waiting_time:5.1f}s, "
                      f"Phase = {info.get('current_phase', 'N/A')}")
        
        # Episode summary
        avg_reward_per_step = total_reward / step_count if step_count > 0 else 0
        episode_rewards.append(total_reward)
        
        episode_stats.append({
            'episode': episode + 1,
            'total_reward': total_reward,
            'avg_reward_per_step': avg_reward_per_step,
            'total_waiting_time': total_waiting_time,
            'phase_changes': phase_changes,
            'steps': step_count
        })
        
        print(f"\n Episode {episode + 1} Results:")
        print(f"   Total reward: {total_reward:.1f}")
        print(f"   Average reward per step: {avg_reward_per_step:.2f}")
        print(f"   Final waiting time: {total_waiting_time:.1f} seconds")
        print(f"   Phase changes: {phase_changes}")
        print(f"   Simulation steps: {step_count}")
    
    # Overall summary
    print("\n" + "=" * 60)
    print("üéØ OVERALL AI PERFORMANCE SUMMARY")
    print("=" * 60)
    
    avg_total_reward = np.mean(episode_rewards)
    std_total_reward = np.std(episode_rewards)
    
    print(f"Average episode reward: {avg_total_reward:.1f} ¬± {std_total_reward:.1f}")
    print(f"Best episode reward: {max(episode_rewards):.1f}")
    print(f"Worst episode reward: {min(episode_rewards):.1f}")
    
    avg_waiting = np.mean([s['total_waiting_time'] for s in episode_stats])
    avg_phase_changes = np.mean([s['phase_changes'] for s in episode_stats])
    
    print(f"Average waiting time per episode: {avg_waiting:.1f} seconds")
    print(f"Average phase changes per episode: {avg_phase_changes:.1f}")
    
    return episode_stats


def test_ai_intelligence(model, env):
    """
    Test specific scenarios to show model intelligence.
    """

    print("\n Testing model intelligence")
    print("=" * 40)
    print("Let's see how the AI handles specific traffic scenarios...")
    
    # Reset environment
    obs, info = env.reset()
    
    # Run a few steps and analyze decisions
    for step in range(10):
        action, _states = model.predict(obs, deterministic=True)
        obs, reward, terminated, truncated, info = env.step(action)
        
        if terminated or truncated:
            break
            
        # Analyze current state
        incoming_vehicles = obs[:4]  # N, E, S, W incoming
        waiting_times = obs[8:12]   # N, E, S, W waiting times
        current_phase = np.argmax(obs[16:20])  # Current traffic light phase
        
        print(f"\nStep {step + 1}:")
        print(f"  üöó Vehicles waiting: N={incoming_vehicles[0]:.0f}, E={incoming_vehicles[1]:.0f}, "
              f"S={incoming_vehicles[2]:.0f}, W={incoming_vehicles[3]:.0f}")
        print(f"  ‚è∞ Waiting times: N={waiting_times[0]:.1f}s, E={waiting_times[1]:.1f}s, "
              f"S={waiting_times[2]:.1f}s, W={waiting_times[3]:.1f}s")
        print(f"  üö¶ AI chose action {action} (phase {current_phase})")
        print(f"  üéÅ Reward: {reward:.1f}")
        
        # Analyze AI's decision
        max_waiting_direction = np.argmax(waiting_times)
        direction_names = ['North', 'East', 'South', 'West']
        
        if incoming_vehicles[max_waiting_direction] > 0:
            print(f" Logic: Most congestion in {direction_names[max_waiting_direction]} direction")


def main():
    """Main demonstration function."""
    print("Trained AI Traffic Control Demonstration")
    print("Headless Mode")
    print()
    
    # Find the trained model
    model_path = "models/ppo_traffic_final_20250630_183234.zip"
    
    if not os.path.exists(model_path):
        # Try to find the latest checkpoint
        checkpoint_files = [f for f in os.listdir("models/checkpoints/") if f.endswith('.zip')]
        if checkpoint_files:
            latest_checkpoint = sorted(checkpoint_files)[-1]
            model_path = f"models/checkpoints/{latest_checkpoint}"
            print(f"‚ö†Ô∏è  Using latest checkpoint: {model_path}")
        else:
            print("‚ùå No trained model found!")
            return
    
    try:
        # Load trained agent
        model = load_trained_agent(model_path)
        
        # Default to headless mode for faster execution
        use_gui = False
        print("Headless mode")
        
        # Create environment
        print(f"\nCreating demonstration environment (GUI: {use_gui})...")
        env = create_demo_environment(use_gui=use_gui)
        print("Environment ready")
        
        # Run demonstration
        episode_stats = demonstrate_ai_control(model, env, episodes=3, use_gui=use_gui)
        
        # Test AI intelligence
        test_ai_intelligence(model, env)
        
        print("\nDemonstration completed")
        
    except Exception as e:
        print(f"‚ùå Error during demonstration: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        print("\nCleaning up...")
        try:
            env.close()
        except:
            pass
        print("‚úÖ Demo completed!")


if __name__ == "__main__":
    main() 